name: full-ci

on:
  workflow_dispatch:
  push:
    branches:
      - main

permissions:
  contents: write

jobs:
  fusion-sweep:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        fusion: [early, late, hybrid]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Set up uv
        uses: astral-sh/setup-uv@v7
        with:
          python-version: "3.13"
          activate-environment: "true"
      - name: Sync dependencies
        run: uv sync
      - name: Train ${{ matrix.fusion }} fusion
        env:
          HYDRA_FULL_ERROR: "1"
        run: |
          uv run python src/train.py \
            model.fusion_type=${{ matrix.fusion }} \
            training.max_epochs=10 \
            experiment.name=a2_${{ matrix.fusion }}_pamap2
      - name: Evaluate ${{ matrix.fusion }} fusion
        env:
          FUSION: ${{ matrix.fusion }}
        run: |
          set -euo pipefail
          export RESULTS_FILE="runs/a2_${FUSION}_pamap2/results.json"
          BEST_CKPT=$(python - <<'PY'
          import json, os
          from pathlib import Path
          results = Path(os.environ["RESULTS_FILE"])
          data = json.load(results.open())
          print(data["best_model_path"])
          PY
          )
          OUT_DIR="experiments/${FUSION}"
          mkdir -p "${OUT_DIR}"
          uv run python src/eval.py --checkpoint "${BEST_CKPT}" --output_dir "${OUT_DIR}" --device cpu --missing_modality_test --analysis_dir analysis/${FUSION}
      - name: Generate analysis plots
        run: |
          uv run python src/analysis.py --experiment_dir experiments --output_dir analysis
      - name: Package fusion artifacts
        env:
          FUSION: ${{ matrix.fusion }}
        run: |
          set -euo pipefail
          DEST="artifacts/fusion/${FUSION}"
          mkdir -p "${DEST}/runs" "${DEST}/experiments" "${DEST}/analysis/fusion"
          cp -r "runs/a2_${FUSION}_pamap2" "${DEST}/runs/"
          cp -r "experiments/${FUSION}" "${DEST}/experiments/"
          mkdir -p "${DEST}/analysis/fusion"
          cp -r "analysis/${FUSION}" "${DEST}/analysis/fusion/"
      - name: Upload fusion artifacts
        uses: actions/upload-artifact@v4
        with:
          name: fusion-${{ matrix.fusion }}
          path: artifacts/fusion/${{ matrix.fusion }}

  heads-ablation:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        heads: [1, 4, 8]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: astral-sh/setup-uv@v7
        with:
          python-version: "3.13"
          activate-environment: "true"
      - run: uv sync
      - name: Train num_heads=${{ matrix.heads }}
        env:
          HYDRA_FULL_ERROR: "1"
        run: |
          uv run python src/train.py \
            model.fusion_type=hybrid \
            model.num_heads=${{ matrix.heads }} \
            training.max_epochs=10 \
            experiment.name=a2_hybrid_heads${{ matrix.heads }}
      - name: Evaluate num_heads=${{ matrix.heads }}
        env:
          HEADS: ${{ matrix.heads }}
        run: |
          set -euo pipefail
          export RESULTS_FILE="runs/a2_hybrid_heads${HEADS}/results.json"
          CKPT=$(python - <<'PY'
          import json, os
          from pathlib import Path
          results = Path(os.environ["RESULTS_FILE"])
          data = json.load(results.open())
          print(data["best_model_path"])
          PY
          )
          OUT_DIR="experiments/heads_${HEADS}"
          mkdir -p "${OUT_DIR}"
          uv run python src/eval.py --checkpoint "${CKPT}" --output_dir "${OUT_DIR}" --device cpu --analysis_dir analysis_heads
      - run: uv run python src/analysis.py --experiment_dir experiments --output_dir analysis_heads
      - name: Package heads artifacts
        env:
          HEADS: ${{ matrix.heads }}
        run: |
          set -euo pipefail
          DEST="artifacts/heads/${HEADS}"
          mkdir -p "${DEST}/runs" "${DEST}/experiments" "${DEST}/analysis/heads"
          cp -r "runs/a2_hybrid_heads${HEADS}" "${DEST}/runs/"
          cp -r "experiments/heads_${HEADS}" "${DEST}/experiments/"
          mkdir -p "${DEST}/analysis/heads"
          cp -r "analysis_heads" "${DEST}/analysis/heads/${HEADS}"
      - uses: actions/upload-artifact@v4
        with:
          name: heads-${{ matrix.heads }}
          path: artifacts/heads/${{ matrix.heads }}

  chunks-ablation:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [512, 1024, 2048]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: astral-sh/setup-uv@v7
        with:
          python-version: "3.13"
          activate-environment: "true"
      - run: uv sync
      - name: Train chunk=${{ matrix.chunk }}
        env:
          HYDRA_FULL_ERROR: "1"
        run: |
          uv run python src/train.py \
            model.fusion_type=hybrid \
            dataset.chunk_size=${{ matrix.chunk }} \
            training.max_epochs=15 \
            experiment.name=a2_hybrid_chunk${{ matrix.chunk }}
      - name: Evaluate chunk=${{ matrix.chunk }}
        env:
          CHUNK: ${{ matrix.chunk }}
        run: |
          set -euo pipefail
          export RESULTS_FILE="runs/a2_hybrid_chunk${CHUNK}/results.json"
          CKPT=$(python - <<'PY'
          import json, os
          from pathlib import Path
          results = Path(os.environ["RESULTS_FILE"])
          data = json.load(results.open())
          print(data["best_model_path"])
          PY
          )
          OUT_DIR="experiments/chunk_${CHUNK}"
          mkdir -p "${OUT_DIR}"
          uv run python src/eval.py --checkpoint "${CKPT}" --output_dir "${OUT_DIR}" --device cpu --analysis_dir analysis_chunk
      - run: uv run python src/analysis.py --experiment_dir experiments --output_dir analysis_chunk
      - name: Package chunk artifacts
        env:
          CHUNK: ${{ matrix.chunk }}
        run: |
          set -euo pipefail
          DEST="artifacts/chunk/${CHUNK}"
          mkdir -p "${DEST}/runs" "${DEST}/experiments" "${DEST}/analysis/chunk"
          cp -r "runs/a2_hybrid_chunk${CHUNK}" "${DEST}/runs/"
          cp -r "experiments/chunk_${CHUNK}" "${DEST}/experiments/"
          mkdir -p "${DEST}/analysis/chunk"
          cp -r "analysis_chunk" "${DEST}/analysis/chunk/${CHUNK}"
      - uses: actions/upload-artifact@v4
        with:
          name: chunk-${{ matrix.chunk }}
          path: artifacts/chunk/${{ matrix.chunk }}

  single-modality-sweep:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        modality: [imu_hand, imu_chest, imu_ankle, heart_rate]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: astral-sh/setup-uv@v7
        with:
          python-version: "3.13"
          activate-environment: "true"
      - run: uv sync
      - name: Train single-modality ${{ matrix.modality }}
        env:
          HYDRA_FULL_ERROR: "1"
        run: |
          uv run python src/train.py \
            model.fusion_type=early \
            dataset.modalities=[${{ matrix.modality }}] \
            training.max_epochs=10 \
            experiment.name=a2_single_${{ matrix.modality }}
      - name: Evaluate single-modality ${{ matrix.modality }}
        env:
          MOD: ${{ matrix.modality }}
        run: |
          set -euo pipefail
          export RESULTS_FILE="runs/a2_single_${MOD}/results.json"
          CKPT=$(python - <<'PY'
          import json, os
          from pathlib import Path
          results = Path(os.environ["RESULTS_FILE"])
          data = json.load(results.open())
          print(data["best_model_path"])
          PY
          )
          OUT_DIR="experiments/single_${MOD}"
          mkdir -p "${OUT_DIR}"
          uv run python src/eval.py --checkpoint "${CKPT}" --output_dir "${OUT_DIR}" --device cpu --analysis_dir analysis_single
      - run: uv run python src/analysis.py --experiment_dir experiments --output_dir analysis_single
      - name: Package single-modality artifacts
        env:
          MOD: ${{ matrix.modality }}
        run: |
          set -euo pipefail
          DEST="artifacts/single/${MOD}"
          mkdir -p "${DEST}/runs" "${DEST}/experiments" "${DEST}/analysis/single"
          cp -r "runs/a2_single_${MOD}" "${DEST}/runs/"
          cp -r "experiments/single_${MOD}" "${DEST}/experiments/"
          mkdir -p "${DEST}/analysis/single"
          cp -r "analysis_single" "${DEST}/analysis/single/${MOD}"
      - uses: actions/upload-artifact@v4
        with:
          name: single-${{ matrix.modality }}
          path: artifacts/single/${{ matrix.modality }}

  merge:
    runs-on: ubuntu-latest
    needs:
      - fusion-sweep
      - heads-ablation
      - chunks-ablation
      - single-modality-sweep
    concurrency:
      group: artifact-push-${{ github.ref }}
      cancel-in-progress: false
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: "*"
          merge-multiple: false
          path: artifacts
      - name: Merge downloaded artifacts
        run: |
          set -euo pipefail
          mkdir -p runs experiments analysis
          shopt -s nullglob
          for pkg in artifacts/*/*; do
            cp -R "$pkg/runs/." runs/ 2>/dev/null || true
            cp -R "$pkg/experiments/." experiments/ 2>/dev/null || true
            cp -R "$pkg/analysis/." analysis/ 2>/dev/null || true
          done
      - uses: astral-sh/setup-uv@v7
        with:
          python-version: "3.13"
          activate-environment: "true"
      - run: uv sync
      - name: Generate fused plots
        run: |
          set -euo pipefail
          uv run python src/analysis.py --experiment_dir experiments --output_dir analysis --fusion_file experiments/fusion_comparison.json
      - name: Aggregate fusion metrics
        run: |
          set -euo pipefail
          python - <<'PY'
          from pathlib import Path
          import json
          
          base = Path("experiments")
          results = {"results": {}}
          for fusion_dir in sorted(base.iterdir()):
              eval_file = fusion_dir / "evaluation_results.json"
              if eval_file.exists():
                  results["results"][fusion_dir.name] = json.load(eval_file.open())
          
          (base / "fusion_comparison.json").write_text(json.dumps(results, indent=2))
          PY
      - name: Commit artifacts
        run: |
          set -euo pipefail
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git checkout "${{ github.head_ref || github.ref_name }}"
          git pull --ff-only origin "${{ github.head_ref || github.ref_name }}"
          git add runs
          git add experiments
          git add analysis
          git commit -m "ci: merge artifacts" || echo "No changes to commit"
          git push origin "${{ github.head_ref || github.ref_name }}"
